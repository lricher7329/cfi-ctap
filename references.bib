@techreport{2021,
  type = {Report},
  title = {{{UK}} Biobank {{SARS-CoV-2}} Serology Study},
  year = 2021,
  keywords = {neurometabolism}
}

@article{aghakasiri2025,
  title = {Not What the Doctor Ordered: {{Surveying LLM-based}} de-Identification and Quantifying Clinical Information Loss},
  author = {Aghakasiri, Kiana and Zambare, Noopur and Thai, JoAnn and Ye, Carrie and Mehta, Mayur and Mitchell, J Ross and Abdalla, Mohamed},
  year = 2025,
  journal = {arXiv},
  eprint = {2509.14464},
  doi = {10.48550/arxiv.2509.14464},
  abstract = {De-identification in the healthcare setting is an application of NLP where automated algorithms are used to remove personally identifying information of patients (and, sometimes, providers). With the recent rise of generative large language models (LLMs), there has been a corresponding rise in the number of papers that apply LLMs to de-identification. Although these approaches often report near-perfect results, significant challenges concerning reproducibility and utility of the research papers persist. This paper identifies three key limitations in the current literature: inconsistent reporting metrics hindering direct comparisons, the inadequacy of traditional classification metrics in capturing errors which LLMs may be more prone to (i.e., altering clinically relevant information), and lack of manual validation of automated metrics which aim to quantify these errors. To address these issues, we first present a survey of LLM-based de-identification research, highlighting the heterogeneity in reporting standards. Second, we evaluated a diverse set of models to quantify the extent of inappropriate removal of clinical information. Next, we conduct a manual validation of an existing evaluation metric to measure the removal of clinical information, employing clinical experts to assess their efficacy. We highlight poor performance and describe the inherent limitations of such metrics in identifying clinically significant changes. Lastly, we propose a novel methodology for the detection of clinically relevant information removal.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers}
}

@article{allen2011,
  title = {Reconsidering the Value of Consent in Biobank Research.},
  author = {Allen, Judy and McNamara, Beverley},
  year = 2011,
  journal = {Bioethics},
  volume = {25},
  pages = {155--166},
  abstract = {Biobanks for long-term research pose challenges to the legal and ethical validity of consent to participate. Different models of consent have been proposed to answer some of these challenges. This paper contributes to this discussion by considering the meaning and value of consent to participants in biobanks. Empirical data from a qualitative study is used to provide a participant view of the consent process and to demonstrate that, despite limited understanding of the research, consent provides the research participants with some level of control and a form of self determination that they value. Participation is framed as a moral act of a responsible citizen providing reinforcement of self identity. Consent symbolizes the trust invested in researchers and research institutions to use the biobank for the public good. The paper argues that consent continues to play an important role in biobank participation and that a participant view should inform proposals to modify consent processes.},
  rating = {0},
  keywords = {biobanking,ethics,research informatics,research methods}
}

@article{antoniades2021,
  title = {Integration of Biobanks in National {{eHealth}} Ecosystems Facilitating Long-Term Longitudinal Clinical-Omics Studies and Citizens' Engagement in Research through {{eHealthBioR}}},
  author = {Antoniades, Athos and Papaioannou, Maria and Malatras, Apostolos and Papagregoriou, Gregory and M{\"u}ller, Heimo and Holub, Petr and Deltas, Constantinos and Schizas, Christos N.},
  year = 2021,
  journal = {Frontiers in Digital Health},
  volume = {3},
  pages = {628646},
  doi = {10.3389/fdgth.2021.628646},
  abstract = {Biobanks have long existed to support research activities with BBMRI-ERIC formed as a European research infrastructure supporting the coordination for biobanking with 20 country members and one international organization. Although the benefits of biobanks to the research community are well-established, the direct benefit to citizens is limited to the generic benefit of promoting future research. Furthermore, the advent of General Data Protection Regulation (GDPR) legislation raised a series of challenges for scientific research especially related to biobanking associate activities and longitudinal research studies. Electronic health record (EHR) registries have long existed in healthcare providers. In some countries, even at the national level, these record the state of the health of citizens through time for the purposes of healthcare and data portability between different providers. The potential of EHRs in research is great and has been demonstrated in many projects that have transformed EHR data into retrospective medical history information on participating subjects directly from their physician's collected records; many key challenges, however, remain. In this paper, we present a citizen-centric framework called eHealthBioR, which would enable biobanks to link to EHR systems, thus enabling not just retrospective but also lifelong prospective longitudinal studies of participating citizens. It will also ensure strict adherence to legal and ethical requirements, enabling greater control that encourages participation. Citizens would benefit from the real and direct control of their data and samples, utilizing technology, to empower them to make informed decisions about providing consent and practicing their rights related to the use of their data, as well as by having access to knowledge and data generated from samples they provided to biobanks. This is expected to motivate patient engagement in future research and even leads to participatory design methodologies with citizen/patient-centric designed studies. The development of platforms based on the eHealthBioR framework would need to overcome significant challenges. However, it would shift the burden of addressing these to experts in the field while providing solutions enabling in the long term the lower monetary and time cost of longitudinal studies coupled with the option of lifelong monitoring through EHRs.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC8521893},
  pmid = {34713101},
  keywords = {biobanking,emr}
}

@article{baghelani2020noninvasive-b2d,
  title = {Non-Invasive Continuous-Time Glucose Monitoring System Using a Chipless Printable Sensor Based on Split Ring Microwave Resonators},
  author = {Baghelani, Masoud and Abbasi, Zahra and Daneshmand, Mojgan and Light, Peter E.},
  year = 2020,
  journal = {Scientific Reports},
  volume = {10},
  number = {1},
  pages = {12980},
  doi = {10.1038/s41598-020-69547-1},
  abstract = {This paper reports a highly sensitive, non-invasive sensor for real-time glucose monitoring from interstitial fluid. The structure is comprised of a chip-less tag sensor which may be taped over the patient's skin and a reader, that can be embedded in a smartwatch. The tag sensor is energized through the established electromagnetic coupling between the tag and the reader and its frequency response is reflected on the spectrum of the reader in the same manner. The tag sensor consumes zero power as there is no requirement for any active readout or communication circuitry on the tag side. When measuring changes in glucose concentrations within saline replicating interstitial fluid, the sensor was able to detect glucose with an accuracy of \textasciitilde{} 1 mM/l over a physiological range of glucose concentrations with 38 kHz of the resonance frequency shift. This high sensitivity is attained as a result of the proposed new design and extended field concentration on the tag. The impact of some of the possible interferences on the response of the sensor's performance was also investigated. Variations in electrolyte concentrations within the test samples have a negligible effect on the response of the sensor unless these variations are supra-physiologically large.},
  pmcid = {PMC7395170},
  pmid = {32737348}
}

@article{barazzetti2020,
  title = {Broad Consent in Practice: Lessons Learned from a Hospital-Based Biobank for Prospective Research on Genomic and Medical Data},
  author = {Barazzetti, Gaia and Bosisio, Francesca and Koutaissoff, Daria and Spencer, Brenda},
  year = 2020,
  journal = {European Journal of Human Genetics},
  volume = {28},
  number = {7},
  pages = {915--924},
  issn = {1018-4813},
  doi = {10.1038/s41431-020-0585-0},
  abstract = {Broad consent is increasingly recommended as an acceptable consent model for biobanking human samples and health data with a view to their future use in research. Empirical evidence on the practice of broad consent and its implementation in the hospital setting, however, is still very limited. We analyse and discuss results from a qualitative study of perceptions of a sample of patients and biobank recruiters regarding broad consent to participate in a hospital-based biobank for prospective research on genomic and health data. Our findings suggest that contextual and relational factors play an important role in the practice of broad consent, and illustrate that broad consent relies as much on intuition as on reasoning. Moreover, we show that seeking broad consent in the hospital affects patient-recruiter interaction and that ``conditional'' trust plays a significant role in broad-consent decision-making. In conclusion, we provide recommendations to improve patient autonomy in the context of hospital-based broad consent.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC7316733},
  pmid = {32086443},
  keywords = {research informatics,research methods}
}

@article{beck2020artificial-7a6,
  title = {Artificial Intelligence Tool for Optimizing Eligibility Screening for Clinical Trials in a Large Community Cancer Center},
  author = {Beck, J. Thaddeus and Rammage, Melissa and Jackson, Gretchen P. and Preininger, Anita M. and {Dankwa-Mullan}, Irene and Roebuck, M. Christopher and Torres, Adam and Holtzen, Helen and Coverdill, Sadie E. and Williamson, M. Paul and Chau, Quincy and Rhee, Kyu and Vinegra, Michael},
  year = 2020,
  journal = {JCO Clinical Cancer Informatics},
  number = {4},
  pages = {50--59},
  issn = {2473-4276},
  doi = {10.1200/cci.19.00079},
  abstract = {PURPOSE Less than 5\% of patients with cancer enroll in clinical trials, and 1 in 5 trials are stopped for poor accrual. We evaluated an automated clinical trial matching system that uses natural language processing to extract patient and trial characteristics from unstructured sources and machine learning to match patients to clinical trials. PATIENTS AND METHODS Medical records from 997 patients with breast cancer were assessed for trial eligibility at Highlands Oncology Group between May and August 2016. System and manual attribute extraction and eligibility determinations were compared using the percentage of agreement for 239 patients and 4 trials. Sensitivity and specificity of system-generated eligibility determinations were measured, and the time required for manual review and system-assisted eligibility determinations were compared. RESULTS Agreement between system and manual attribute extraction ranged from 64.3\% to 94.0\%. Agreement between system and manual eligibility determinations was 81\%-96\%. System eligibility determinations demonstrated specificities between 76\% and 99\%, with sensitivities between 91\% and 95\% for 3 trials and 46.7\% for the 4th. Manual eligibility screening of 90 patients for 3 trials took 110 minutes; system-assisted eligibility determinations of the same patients for the same trials required 24 minutes. CONCLUSION In this study, the clinical trial matching system displayed a promising performance in screening patients with breast cancer for trial eligibility. System-assisted trial eligibility determinations were substantially faster than manual review, and the system reliably excluded ineligible patients for all trials and identified eligible patients for most trials.},
  langid = {english}
}

@article{beesley2020,
  title = {The Emerging Landscape of Health Research Based on Biobanks Linked to Electronic Health Records: {{Existing}} Resources, Statistical Challenges, and Potential Opportunities},
  author = {Beesley, Lauren J. and Salvatore, Maxwell and Fritsche, Lars G. and Pandit, Anita and Rao, Arvind and Brummett, Chad and Willer, Cristen J. and Lisabeth, Lynda D. and Mukherjee, Bhramar},
  year = 2020,
  journal = {Statistics in Medicine},
  volume = {39},
  number = {6},
  pages = {773--800},
  issn = {0277-6715},
  doi = {10.1002/sim.8445},
  abstract = {Biobanks linked to electronic health records provide rich resources for health-related research. With improvements in administrative and informatics infrastructure, the availability and utility of data from biobanks have dramatically increased. In this paper, we first aim to characterize the current landscape of available biobanks and to describe specific biobanks, including their place of origin, size, and data types. The development and accessibility of large-scale biorepositories provide the opportunity to accelerate agnostic searches, expedite discoveries, and conduct hypothesis-generating studies of disease-treatment, disease-exposure, and disease-gene associations. Rather than designing and implementing a single study focused on a few targeted hypotheses, researchers can potentially use biobanks' existing resources to answer an expanded selection of exploratory questions as quickly as they can analyze them. However, there are many obvious and subtle challenges with the design and analysis of biobank-based studies. Our second aim is to discuss statistical issues related to biobank research such as study design, sampling strategy, phenotype identification, and missing data. We focus our discussion on biobanks that are linked to electronic health records. Some of the analytic issues are illustrated using data from the Michigan Genomics Initiative and UK Biobank, two biobanks with two different recruitment mechanisms. We summarize the current body of literature for addressing these challenges and discuss some standing open problems. This work complements and extends recent reviews about biobank-based research and serves as a resource catalog with analytical and practical guidance for statisticians, epidemiologists, and other medical researchers pursuing research using biobanks.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC7983809},
  pmid = {31859414},
  keywords = {biobanking,bioinformatics,emr,research informatics,research methods}
}

@techreport{Bell,
  title = {Life Sciences Industrial Strategy},
  author = {Bell, John},
  keywords = {\clinical trials,\precision health,\strategic plan}
}

@misc{besevic2021,
  title = {{{UK}} Biobank {{SARS-CoV-2}} Serology Study},
  author = {Besevic, J and Biobank, {\relax UK}},
  year = 2021,
  urldate = {2023-08-01},
  howpublished = {https://policycommons.net/artifacts/1729543/uk-biobank-sars-cov-2-serology-study/2461192/},
  keywords = {neurometabolism}
}

@article{bowton2014,
  title = {Biobanks and Electronic Medical Records: {{Enabling}} Cost-Effective Research},
  author = {Bowton, Erica and Field, Julie R. and Wang, Sunny and Schildcrout, Jonathan S. and Driest, Sara L. Van and Delaney, Jessica T. and Cowan, James and Weeke, Peter and Mosley, Jonathan D. and Wells, Quinn S. and Karnes, Jason H. and Shaffer, Christian and Peterson, Josh F. and Denny, Joshua C. and Roden, Dan M. and Pulley, Jill M.},
  year = 2014,
  journal = {Science Translational Medicine},
  volume = {6},
  number = {234},
  pages = {234cm3--234cm3},
  issn = {1946-6234},
  doi = {10.1126/scitranslmed.3008604},
  abstract = {The use of electronic medical record data linked to biological specimens in health care settings is expected to enable cost-effective and rapid genomic analyses. Here, we present a model that highlights potential advantages for genomic discovery and describe the operational infrastructure that facilitated multiple simultaneous discovery efforts.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC4226414},
  pmid = {24786321},
  rating = {0},
  keywords = {biobanking,emr,informatics,research informatics,research methods}
}

@article{bramley2024,
  title = {Health {{Outcomes Linkage}} in {{UK Biobank}}},
  author = {Bramley, Laura and Gay, Jo and De Lacy, Christopher and Callen, Howard and Rose, Sean and Flaxman, Amy and Codner, Gemma and {Drake-Brockman}, Rachael and Lacey, Ben and Allen, Naomi},
  year = 2024,
  month = sep,
  journal = {International Journal of Population Data Science},
  volume = {9},
  number = {5},
  issn = {2399-4908},
  doi = {10.23889/ijpds.v9i5.2771},
  urldate = {2025-12-26},
  abstract = {UK Biobank is a biomedical database~containing~de-identified data for~over 500,000~participants~within the United Kingdom,~made~globally~available to researchers~for~health-related research in the public interest.~To obtain~comprehensive~health outcome~data,~UK Biobank links to participants' electronic medical record (EHR) data from the National Health Service (NHS)~amongst~others.~This~currently~involves fifteen~data~pipelines~covering death and cancer registries, inpatient records, primary care records, and COVID-19 test and vaccination data, with~numerous~others planned.~  Integrating~diverse ``real-world'' datasets into the~resource~necessitates~a complex~data~infrastructure~and thorough quality assurance.~Challenges~include~file format changes,~linkage problems,~incomplete or invalid records, problems with encoding systems~and~discordances between different data sources.~~  Various~methods can be used to~integrate~data~into the resource, including commercial software, internally developed tools, and custom-scripted pipelines for individual feeds.~To streamline and standardize data processing, we are trialing a~new~data~integration architecture and toolset.~This aims to reduce~manual input, and~improve~transparency, quality assurance and efficiency within and between data pipelines.~  The pilot is currently ongoing with results~expected~in mid-2024.~We~anticipate~these new tools will help to streamline the end-to-end process,~which will~allow~the~data analysis and linkage teams~to focus on further improving data~quality~and~providing~more `research-ready'~summary~outputs~on~researchers'~health outcomes~of interest.~The~findings of the~pilot will~be relevant~to~researchers~and data scientists looking to employ~cutting-edge~approaches~to linkage of~any~large-scale population data.},
  copyright = {http://creativecommons.org/licenses/by/4.0},
  file = {/Users/lawrencericher/Zotero/storage/29YRYJFN/Bramley et al. - 2024 - Health Outcomes Linkage in UK Biobank.pdf}
}

@article{brancato2024,
  title = {Standardizing Digital Biobanks: Integrating Imaging, Genomic, and Clinical Data for Precision Medicine},
  shorttitle = {Standardizing Digital Biobanks},
  author = {Brancato, Valentina and Esposito, Giuseppina and Coppola, Luigi and Cavaliere, Carlo and Mirabelli, Peppino and Scapicchio, Camilla and Borgheresi, Rita and Neri, Emanuele and Salvatore, Marco and Aiello, Marco},
  year = 2024,
  month = feb,
  journal = {Journal of Translational Medicine},
  volume = {22},
  number = {1},
  pages = {136},
  issn = {1479-5876},
  doi = {10.1186/s12967-024-04891-8},
  urldate = {2025-12-26},
  abstract = {Abstract             Advancements in data acquisition and computational methods are generating a large amount of heterogeneous biomedical data from diagnostic domains such as clinical imaging, pathology, and next-generation sequencing (NGS), which help characterize individual differences in patients. However, this information needs to be available and suitable to promote and support scientific research and technological development, supporting the effective adoption of the precision medicine approach in clinical practice.~Digital biobanks can catalyze this process, facilitating the sharing of curated and standardized imaging data, clinical, pathological and molecular data, crucial to enable the development of a comprehensive and personalized data-driven diagnostic approach in disease management and fostering the development of computational predictive models.~This work aims to frame this perspective, first by evaluating the state of standardization of individual diagnostic domains and then by identifying challenges and proposing a possible solution towards an integrative approach that can guarantee the suitability of information that can be shared through a digital biobank.~Our analysis of the state of the art shows the presence and use of reference standards in biobanks and, generally, digital repositories for each specific domain. Despite this, standardization to guarantee the integration and reproducibility of the numerical descriptors generated by each domain, e.g. radiomic, pathomic and -omic features, is still an open challenge. Based on specific use cases and scenarios, an integration model, based on the JSON format, is proposed that can help address this problem.~Ultimately, this work shows how, with specific standardization and promotion efforts, the digital biobank model can become an enabling technology for the comprehensive study of diseases and the effective development of data-driven technologies at the service of precision medicine.},
  langid = {english},
  file = {/Users/lawrencericher/Zotero/storage/HEY5DDVH/Brancato et al. - 2024 - Standardizing digital biobanks integrating imaging, genomic, and clinical data for precision medici.pdf}
}

@article{brisson2012,
  title = {Translational Research in Pediatrics: {{Tissue}} Sampling and Biobanking},
  author = {Brisson, Alayne R. and Matsui, Doreen and Rieder, Michael J. and Fraser, Douglas D.},
  year = 2012,
  journal = {Pediatrics},
  volume = {129},
  number = {1},
  pages = {153--162},
  issn = {0031-4005},
  doi = {10.1542/peds.2011-0134},
  abstract = {Translational research is expanding and has become a focus of National Research funding agencies, touted as the primary avenue to improve health care practice. The use of human tissues for research on disease etiology is a pillar of translational research, particularly with innovations in research technologies to investigate the building blocks of disease. In pediatrics, translational research using human tissues has been hindered by the many practical and ethical considerations associated with tissue procurement from children and also by a limited population base for study, by the increasing complexities in conducting clinical research, and by a lack of dedicated child-health research funding. Given these obstacles, pediatric translational research can be enhanced by developing strategic and efficient biobanks that will provide scientists with quality tissue specimens to render accurate and reproducible research results. Indeed, tissue sampling and biobanking within pediatric academic settings has potential to impact child health by promoting bidirectional interaction between clinicians and scientists, helping to maximize research productivity, and providing a competitive edge for attracting and maintaining high-quality personnel. The authors of this review outline key issues and practical solutions to optimize pediatric tissue sampling and biobanking for translational research, activities that will ultimately reduce the burden of childhood disease.},
  langid = {english},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmid = {22144705},
  rating = {0},
  keywords = {biobanking}
}

@article{calapricewhitty2019improving-c06,
  title = {Improving Clinical Trial Participant Prescreening with Artificial Intelligence ({{AI}}): A Comparison of the Results of {{AI-assisted}} vs Standard Methods in 3 Oncology Trials},
  author = {{Calaprice-Whitty}, Denise and Galil, Karim and Salloum, Wael and Zariv, Ashkon and Jimenez, Bernal},
  year = 2019,
  journal = {Therapeutic Innovation \& Regulatory Science},
  pages = {216847901881545},
  issn = {2168-4790},
  doi = {10.1177/2168479018815454},
  abstract = {BACKGROUND:: Delays in clinical trial enrollment and difficulties enrolling representative samples continue to vex sponsors, sites, and patient populations. Here we investigated use of an artificial intelligence-powered technology, Mendel.ai, as a means of overcoming bottlenecks and potential biases associated with standard patient prescreening processes in an oncology setting. METHODS:: Mendel.ai was applied retroactively to 2 completed oncology studies (1 breast, 1 lung), and 1 study that failed to enroll (lung), at the Comprehensive Blood and Cancer Center, allowing direct comparison between results achieved using standard prescreening practices and results achieved with Mendel.ai. Outcome variables included the number of patients identified as potentially eligible and the elapsed time between eligibility and identification. RESULTS:: For each trial that enrolled, use of Mendel.ai resulted in a 24\% to 50\% increase over standard practices in the number of patients correctly identified as potentially eligible. No patients correctly identified by standard practices were missed by Mendel.ai. For the nonenrolling trial, both approaches failed to identify suitable patients. An average of 19 days for breast and 263 days for lung cancer patients elapsed between actual patient eligibility (based on clinical chart information) and identification when the standard prescreening practice was used. In contrast, ascertainment of potential eligibility using Mendel.ai took minutes. CONCLUSIONS:: This study suggests that augmentation of human resources with artificial intelligence could yield sizable improvements over standard practices in several aspects of the patient prescreening process, as well as in approaches to feasibility, site selection, and trial selection.},
  langid = {english},
  pmid = {30599764}
}

@article{calapricewhitty2020improving-5c9,
  title = {Improving Clinical Trial Participant Prescreening with Artificial Intelligence ({{AI}}): A Comparison of the Results of {{AI-assisted}} vs Standard Methods in 3 Oncology Trials},
  author = {{Calaprice-Whitty}, Denise and Galil, Karim and Salloum, Wael and Zariv, Ashkon and Jimenez, Bernal},
  year = 2020,
  journal = {Therapeutic Innovation \&amp; Regulatory Science},
  volume = {54},
  number = {1},
  pages = {69--74},
  issn = {2168-4790},
  doi = {10.1007/s43441-019-00030-4},
  abstract = {BACKGROUND Delays in clinical trial enrollment and difficulties enrolling representative samples continue to vex sponsors, sites, and patient populations. Here we investigated use of an artificial intelligence-powered technology, Mendel.ai, as a means of overcoming bottlenecks and potential biases associated with standard patient prescreening processes in an oncology setting. METHODS Mendel.ai was applied retroactively to 2 completed oncology studies (1 breast, 1 lung), and 1 study that failed to enroll (lung), at the Comprehensive Blood and Cancer Center, allowing direct comparison between results achieved using standard prescreening practices and results achieved with Mendel.ai. Outcome variables included the number of patients identified as potentially eligible and the elapsed time between eligibility and identification. RESULTS For each trial that enrolled, use of Mendel.ai resulted in a 24\% to 50\% increase over standard practices in the number of patients correctly identified as potentially eligible. No patients correctly identified by standard practices were missed by Mendel.ai. For the nonenrolling trial, both approaches failed to identify suitable patients. An average of 19 days for breast and 263 days for lung cancer patients elapsed between actual patient eligibility (based on clinical chart information) and identification when the standard prescreening practice was used. In contrast, ascertainment of potential eligibility using Mendel.ai took minutes. CONCLUSIONS This study suggests that augmentation of human resources with artificial intelligence could yield sizable improvements over standard practices in several aspects of the patient prescreening process, as well as in approaches to feasibility, site selection, and trial selection.},
  langid = {english}
}

@article{chen2025,
  title = {Enhancing {{Patient-Trial Matching With Large Language Models}}: {{A Scoping Review}} of {{Emerging Applications}} and {{Approaches}}},
  shorttitle = {Enhancing {{Patient-Trial Matching With Large Language Models}}},
  author = {Chen, Hongyu and Li, Xiaohan and He, Xing and Chen, Aokun and McGill, James and Webber, Emily C. and Xu, Hua and Liu, Mei and Bian, Jiang},
  year = 2025,
  month = jun,
  journal = {JCO Clinical Cancer Informatics},
  number = {9},
  pages = {e2500071},
  issn = {2473-4276},
  doi = {10.1200/CCI-25-00071},
  urldate = {2025-12-26},
  abstract = {PURPOSE               Patient recruitment remains a major bottleneck in clinical trial execution, with inefficient patient-trial matching often causing delays and failures. Recent advancements in large language models (LLMs) offer a promising avenue for automating and improving this process. This scoping review aims to provide a comprehensive synthesis of the emerging applications of LLMs in patient-trial matching.                                         METHODS               A comprehensive search was conducted in PubMed, Web of Science, and OpenAlex for literature published between December 1, 2022, and December 31, 2024. Studies were included if they explicitly integrated LLMs into patient-trial matching systems. Data extraction focused on system architectures, patient data processing, eligibility criteria processing, matching techniques, evaluation metrics, and performance.                                         RESULTS               Of the 2,357 studies initially identified, 24 met the inclusion criteria. The majority (21/24) were published in 2024, highlighting the rapid adoption of LLMs in this domain. Most systems used patient-centric matching (17/24), with OpenAI's generative pretrained transformer models being the most commonly used LLM. Core components of these systems included eligibility criteria processing, patient data processing, and matching, with some incorporating retrieval algorithms to enhance computational efficiency. LLM-integrated approaches demonstrated improved accuracy and scalability in patient-trial matching, although challenges such as performance variability, interpretability, and reliance on synthetic data sets remain significant.                                         CONCLUSION               LLM-based patient-trial matching systems present a transformative opportunity to enhance the efficiency and accuracy of clinical trial recruitment. Despite current limitations related to model generalizability, explainability, and data constraints, future advancements in hybrid modeling strategies, domain-specific fine-tuning, and real-world data set integration could further optimize LLM-based trial matching. Addressing these challenges will be crucial to realizing the full potential of LLMs in streamlining patient recruitment and accelerating clinical trial execution.},
  langid = {english}
}

@article{chow2023use-87e,
  title = {Use of Artificial Intelligence for Cancer Clinical Trial Enrollment: A Systematic Review and Meta-Analysis},
  author = {Chow, Ronald and Midroni, Julie and Kaur, Jagdeep and Boldt, Gabriel and Liu, Geoffrey and Eng, Lawson and Liu, Fei-Fei and {Haibe-Kains}, Benjamin and Lock, Michael and Raman, Srinivas},
  year = 2023,
  journal = {JNCI: Journal of the National Cancer Institute},
  volume = {115},
  number = {4},
  pages = {365--374},
  issn = {0027-8874},
  doi = {10.1093/jnci/djad013},
  abstract = {BACKGROUND The aim of this study is to provide a comprehensive understanding of the current landscape of AI for cancer clinical trial enrolment, and its predictive accuracy in identifying eligible patients for inclusion in such trials. METHODS Databases of PubMed, Embase and Cochrane CENTRAL were searched until June 2022. Articles were included if they reported on AI actively being used in the clinical trial enrolment process. Narrative synthesis was conducted amongst all extracted data-accuracy, sensitivity, specificity, positive predictive value, negative predictive value. For studies where the 2x2 contingency table could be calculated or supplied by authors, a meta-analysis to calculate summary statistics was conducted using the hierarchical summary receiver operating characteristics curve model. RESULTS Ten articles, reporting on over 50,000 patients in 19 datasets were included. Accuracy, sensitivity and specificity exceeded 80\% in all but one dataset. Positive predictive value exceeded 80\% in 5 of 17 datasets. Negative predictive value exceeded 80\% in all datasets. Summary sensitivity was 90.5\% (95\% CI: 70.9\%-97.4\%); summary specificity was 99.3\% (95\% CI: 81.8\%-99.9\%). CONCLUSIONS AI demonstrated comparable, if not superior performance to manual screening for patient enrolment into cancer clinical trials. As well, AI is highly efficient, requiring less time and human resources to screen patients. AI should be further investigated and implemented for patient recruitment into cancer clinical trials. Future research should validate the use of AI for clinical trials enrolment in less resource-rich regions, and to ensure broad inclusion for generalizability to all genders, ages and ethnicities.},
  langid = {english}
}

@article{cuggia2011comparing-9d1,
  title = {Comparing Semi-Automatic Systems for Recruitment of Patients to Clinical Trials},
  author = {Cuggia, Marc and Besana, Paolo and Glasspool, David},
  year = 2011,
  journal = {International Journal of Medical Informatics},
  volume = {80},
  number = {6},
  pages = {371--388},
  issn = {1386-5056},
  doi = {10.1016/j.ijmedinf.2011.02.003},
  abstract = {OBJECTIVES (i) To review contributions and limitations of decision support systems for automatic recruitment of patients to clinical trials (Clinical Trial Recruitment Support Systems, CTRSS). (ii) To characterize the important features of this domain, the main classes of approach that have been used, and their advantages and disadvantages. (iii) To assess the effectiveness and potential of such systems in improving trial recruitment rates. DATA SOURCES A systematic MESH keyword-based search of Pubmed, Embase, and Scholar Google for relevant CTRSS publications from January 1st 1998 to August 31st 2009 yielded 73 references, from which 33 relevant papers describing 28 distinct studies were chosen for review, based on their report of a novel decision support system for trial recruitment which reused already available patient data. METHOD The reviewed papers were classified using a modified version of an existing taxonomy for clinical decision support systems, using 10 axes relevant to the trial recruitment domain. RESULTS It proved possible and useful to characterize CTRSS on a relatively small number of dimensions and a number of clear trends emerge from the study. Only nine papers reported a useful evaluation of the effectiveness of the system in terms of trial pre-inclusion or enrolment rate. While all the systems reviewed re-use structured and coded patient data none attempts the more difficult task of using unstructured patient notes to pre-screen for trial inclusion. Few studies address acceptance of systems by clinicians, or integration into clinical workflow, and there is little evidence of use of interoperability standards. CONCLUSIONS System design, scope, and assessment methodology vary significantly between papers, making it difficult to establish the impact of different approaches on recruitment rate. It is clear, however, that the pre-screening phase of trial recruitment is the most effective part of the process to address with CTRSS, that clinical workflow integration and clinician acceptance are critical for this class of decision support, and that the current trends in this field are towards generalization and scalability. Copyright \copyright{} 2011 Elsevier Ireland Ltd. All rights reserved.},
  langid = {english}
}

@article{darke2022,
  title = {Curating a Longitudinal Research Resource Using Linked Primary Care {{EHR}} Data---a {{UK Biobank}} Case Study},
  author = {Darke, Philip and Cassidy, Sophie and Catt, Michael and Taylor, Roy and Missier, Paolo and Bacardit, Jaume},
  year = 2022,
  month = jan,
  journal = {Journal of the American Medical Informatics Association},
  volume = {29},
  number = {3},
  pages = {546--552},
  issn = {1067-5027, 1527-974X},
  doi = {10.1093/jamia/ocab260},
  urldate = {2025-12-26},
  abstract = {Abstract             Primary care EHR data are often of clinical importance to cohort studies however they require careful handling. Challenges include determining the periods during which EHR data were collected. Participants are typically censored when they deregister from a medical practice, however, cohort studies wish to follow participants longitudinally including those that change practice. Using UK Biobank as an exemplar, we developed methodology to infer continuous periods of data collection and maximize follow-up in longitudinal studies. This resulted in longer follow-up for around 40\% of participants with multiple registration records (mean increase of 3.8~years from the first study visit). The approach did not sacrifice phenotyping accuracy when comparing agreement between self-reported and EHR data. A diabetes mellitus case study illustrates how the algorithm supports longitudinal study design and provides further validation. We use UK Biobank data, however, the tools provided can be used for other conditions and studies with minimal alteration.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}

@article{doherty2017,
  title = {Large Scale Population Assessment of Physical Activity Using Wrist Worn Accelerometers: {{The UK}} Biobank Study},
  author = {Doherty, Aiden and Jackson, Dan and Hammerla, Nils and Pl{\"o}tz, Thomas and Olivier, Patrick and Granat, Malcolm H. and White, Tom and van Hees, Vincent T. and Trenell, Michael I. and Owen, Christoper G. and Preece, Stephen J. and Gillions, Rob and Sheard, Simon and Peakman, Tim and Brage, Soren and Wareham, Nicholas J.},
  year = 2017,
  journal = {PLoS ONE},
  volume = {12},
  number = {2},
  pages = {e0169649},
  doi = {10.1371/journal.pone.0169649},
  abstract = {Physical activity has not been objectively measured in prospective cohorts with sufficiently large numbers to reliably detect associations with multiple health outcomes. Technological advances now make this possible. We describe the methods used to collect and analyse accelerometer measured physical activity in over 100,000 participants of the UK Biobank study, and report variation by age, sex, day, time of day, and season. Participants were approached by email to wear a wrist-worn accelerometer for seven days that was posted to them. Physical activity information was extracted from 100Hz raw triaxial acceleration data after calibration, removal of gravity and sensor noise, and identification of wear / non-wear episodes. We report age- and sex-specific wear-time compliance and accelerometer measured physical activity, overall and by hour-of-day, week-weekend day and season. 103,712 datasets were received (44.8\% response), with a median wear-time of 6.9 days (IQR:6.5--7.0). 96,600 participants (93.3\%) provided valid data for physical activity analyses. Vector magnitude, a proxy for overall physical activity, was 7.5\% (2.35mg) lower per decade of age (Cohen's d = 0.9). Women had a higher vector magnitude than men, apart from those aged 45-54yrs. There were major differences in vector magnitude by time of day (d = 0.66). Vector magnitude differences between week and weekend days (d = 0.12 for men, d = 0.09 for women) and between seasons (d = 0.27 for men, d = 0.15 for women) were small. It is feasible to collect and analyse objective physical activity data in large studies. The summary measure of overall physical activity is lower in older participants and age-related differences in activity are most prominent in the afternoon and evening. This work lays the foundation for studies of physical activity and its health consequences. Our summary variables are part of the UK Biobank dataset and can be used by researchers as exposures, confounding factors or outcome variables in future analyses.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC5287488},
  pmid = {28146576},
  keywords = {biobanking,research informatics}
}

@article{douaud2022,
  title = {{{SARS-CoV-2}} Is Associated with Changes in Brain Structure in {{UK Biobank}}},
  author = {Douaud, Gwena{\"e}lle and Lee, Soojin and {Alfaro-Almagro}, Fidel and Arthofer, Christoph and Wang, Chaoyue and McCarthy, Paul and Lange, Frederik and Andersson, Jesper L. R. and Griffanti, Ludovica and Duff, Eugene and Jbabdi, Saad and Taschler, Bernd and Keating, Peter and Winkler, Anderson M. and Collins, Rory and Matthews, Paul M. and Allen, Naomi and Miller, Karla L. and Nichols, Thomas E. and Smith, Stephen M.},
  year = 2022,
  journal = {Nature},
  volume = {604},
  number = {7907},
  pages = {697--707},
  issn = {0028-0836},
  doi = {10.1038/s41586-022-04569-5},
  abstract = {There is strong evidence of brain-related abnormalities in COVID-191--13. However, it remains unknown whether the impact of SARS-CoV-2 infection can be detected in milder cases, and whether this can reveal possible mechanisms contributing to brain pathology. Here we investigated brain changes in 785 participants of UK Biobank (aged 51--81 years) who were imaged twice using magnetic resonance imaging, including 401 cases who tested positive for infection with SARS-CoV-2 between their two scans---with 141 days on average separating their diagnosis and the second scan---as well as 384 controls. The availability of pre-infection imaging data reduces the likelihood of pre-existing risk factors being misinterpreted as disease effects. We identified significant longitudinal effects when comparing the two groups, including (1) a greater reduction in grey matter thickness and tissue contrast in the orbitofrontal cortex and parahippocampal gyrus; (2) greater changes in markers of tissue damage in regions that are functionally connected to the primary olfactory cortex; and (3) a greater reduction in global brain size in the SARS-CoV-2 cases. The participants who were infected with SARS-CoV-2 also showed on average a greater cognitive decline between the two time points. Importantly, these imaging and cognitive longitudinal effects were still observed after excluding the 15 patients who had been hospitalised. These mainly limbic brain imaging results may be the in vivo hallmarks of a degenerative spread of the disease through olfactory pathways, of neuroinflammatory events, or of the loss of sensory input due to anosmia. Whether this deleterious effect can be partially reversed, or whether these effects will persist in the long term, remains to be investigated with additional follow-up. After infection with SARS-CoV-2, individuals show a greater reduction in grey matter thickness and tissue contrast in the orbitofrontal cortex and parahippocampal gyrus; greater changes in markers of tissue damage in regions that are functionally connected to the primary olfactory cortex; and a greater reduction in global brain size.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC9046077},
  pmid = {35255491}
}

@article{dreyer2020,
  title = {{{PRECISION-Panc}}: The {{Next Generation Therapeutic Development Platform}} for {{Pancreatic Cancer}}},
  shorttitle = {{{PRECISION-Panc}}},
  author = {Dreyer, S.B. and Jamieson, N.B. and Cooke, S.L. and Valle, J.W. and McKay, C.J. and Biankin, A.V. and Chang, D.K.},
  year = 2020,
  month = jan,
  journal = {Clinical Oncology},
  volume = {32},
  number = {1},
  pages = {1--4},
  issn = {09366555},
  doi = {10.1016/j.clon.2019.07.011},
  urldate = {2025-12-29},
  langid = {english},
  file = {/Users/lawrencericher/Zotero/storage/VXU4IR8Q/Dreyer et al. - 2020 - PRECISION-Panc the Next Generation Therapeutic Development Platform for Pancreatic Cancer.pdf}
}

@article{ghim2023,
  title = {Transforming Clinical Trials: The Emerging Roles of Large Language Models},
  shorttitle = {Transforming Clinical Trials},
  author = {Ghim, Jong-Lyul and Ahn, Sangzin},
  year = 2023,
  journal = {Translational and Clinical Pharmacology},
  volume = {31},
  number = {3},
  pages = {131},
  issn = {2289-0882, 2383-5427},
  doi = {10.12793/tcp.2023.31.e16},
  urldate = {2025-12-26},
  langid = {english},
  file = {/Users/lawrencericher/Zotero/storage/MKS6BEYA/Ghim and Ahn - 2023 - Transforming clinical trials the emerging roles of large language models.pdf}
}

@article{gibson2008,
  title = {Who's Minding the Shop? {{The}} Role of {{Canadian}} Research Ethics Boards in the Creation and Uses of Registries and Biobanks},
  author = {Gibson, Elaine and Brazil, Kevin and Coughlin, Michael D and Emerson, Claudia and Fournier, Francois and Schwartz, Lisa and {Szala-Meneok}, Karen V and Weisbaum, Karen M and Willison, Donald J},
  year = 2008,
  journal = {BMC Medical Ethics},
  volume = {9},
  number = {1},
  pages = {17},
  doi = {10.1186/1472-6939-9-17},
  abstract = {The amount of research utilizing health information has increased dramatically over the last ten years. Many institutions have extensive biobank holdings collected over a number of years for clinical and teaching purposes, but are uncertain as to the proper circumstances in which to permit research uses of these samples. Research Ethics Boards (REBs) in Canada and elsewhere in the world are grappling with these issues, but lack clear guidance regarding their role in the creation of and access to registries and biobanks. Chairs of 34 REBS and/or REB Administrators affiliated with Faculties of Medicine in Canadian universities were interviewed. Interviews consisted of structured questions dealing with diabetes-related scenarios, with open-ended responses and probing for rationales. The two scenarios involved the development of a diabetes registry using clinical encounter data across several physicians' practices, and the addition of biological samples to the registry to create a biobank. There was a wide range of responses given for the questions raised in the scenarios, indicating a lack of clarity about the role of REBs in registries and biobanks. With respect to the creation of a registry, a minority of sites felt that consent was not required for the information to be entered into the registry. Whether patient consent was required for information to be entered into the registry and the duration for which the consent would be operative differed across sites. With respect to the creation of a biobank linked to the registry, a majority of sites viewed biobank information as qualitatively different from other types of personal health information. All respondents agreed that patient consent was needed for blood samples to be placed in the biobank but the duration of consent again varied. Participants were more attuned to issues surrounding biobanks as compared to registries and demonstrated a higher level of concern regarding biobanks. As registries and biobanks expand, there is a need for critical analysis of suitable roles for REBs and subsequent guidance on these topics. The authors conclude by recommending REB participation in the creation of registries and biobanks and the eventual drafting of comprehensive legislation.},
  langid = {english},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC2636819},
  pmid = {19014594},
  rating = {0},
  keywords = {biobanking,ethics,research informatics,research methods}
}

@article{gkioka2023,
  title = {The {{Organization}} of {{Contemporary Biobanks}} for {{Translational Cancer Research}}},
  author = {Gkioka, Vasiliki and Balaoura, Olga and Goulielmaki, Maria and Baxevanis, Constantin N.},
  year = 2023,
  month = sep,
  journal = {Onco},
  volume = {3},
  number = {4},
  pages = {205--216},
  issn = {2673-7523},
  doi = {10.3390/onco3040015},
  urldate = {2025-12-29},
  abstract = {Cancer biobanks have a crucial role in moving forward the field of translational cancer research and, therefore, have been promoted as indispensable tools for advancing basic biomedical research to preclinical and clinical research, ultimately leading to the design of clinical trials. Consequently, they play an essential role in the establishment of personalized oncology by combining biological data with registries of detailed medical records. The availability of complete electronic medical reports from individualized patients has led to personalized approaches for diagnosis, prognosis, and prediction. To this end, identifying risk factors at early time points is important for designing more effective treatments unique for each patient. Under this aspect, biobanking is essential for accomplishing improvements in the field of precision oncology via the discovery of biomarkers related to cellular and molecular pathways regulating oncogenic signaling. In general terms, biological samples are thought to reflect the patient's disease biology, but under certain conditions, these may also represent responses to various biological stresses. Divergent collection, handling, and storage methods may significantly change biosamples' inherent biological properties. The alteration or loss of biological traits post-collection would lead to the discovery of nonreliable biomarkers and, consequently, to irreproducible results, thus constituting a formidable obstacle regarding the successful translation of preclinical research to clinical approaches. Therefore, a necessary prerequisite for successful biobanking is that the stored biological samples retain their biological characteristics unchanged. The application of quality standards for biospecimen collection and storage could be useful for generating encouraging preclinical data leading to the successful translation to clinical treatment approaches. Herein, we aim to comprehensively review the issues linked to biobank implementation for promoting cancer research.},
  langid = {english},
  file = {/Users/lawrencericher/Zotero/storage/HFIJ66AZ/Gkioka et al. - 2023 - The Organization of Contemporary Biobanks for Translational Cancer Research.pdf}
}

@article{halldorsson2022,
  title = {The Sequences of 150,119 Genomes in the {{UK Biobank}}},
  author = {Halldorsson, Bjarni V. and Eggertsson, Hannes P. and Moore, Kristjan H. S. and Hauswedell, Hannes and Eiriksson, Ogmundur and Ulfarsson, Magnus O. and Palsson, Gunnar and Hardarson, Marteinn T. and Oddsson, Asmundur and Jensson, Brynjar O. and Kristmundsdottir, Snaedis and Sigurpalsdottir, Brynja D. and Stefansson, Olafur A. and Beyter, Doruk and Holley, Guillaume and Tragante, Vinicius and Gylfason, Arnaldur and Olason, Pall I. and Zink, Florian and Asgeirsdottir, Margret and Sverrisson, Sverrir T. and Sigurdsson, Brynjar and Gudjonsson, Sigurjon A. and Sigurdsson, Gunnar T. and Halldorsson, Gisli H. and Sveinbjornsson, Gardar and Norland, Kristjan and Styrkarsdottir, Unnur and Magnusdottir, Droplaug N. and Snorradottir, Steinunn and Kristinsson, Kari and Sobech, Emilia and Jonsson, Helgi and Geirsson, Arni J. and Olafsson, Isleifur and Jonsson, Palmi and Pedersen, Ole Birger and Erikstrup, Christian and Brunak, S{\o}ren and Ostrowski, Sisse Rye and Andersen, Steffen and Banasik, Karina and Burgdorf, Kristoffer and Didriksen, Maria and Dinh, Khoa Manh and Erikstrup, Christian and Gudbjartsson, Daniel and Hansen, Thomas Folkmann and Hjalgrim, Henrik and Jemec, Gregor and Jennum, Poul and Johansson, P{\"a}r Ingemar and Larsen, Margit Anita H{\o}rup and Mikkelsen, Susan and Nielsen, Kasper Rene and Nyegaard, Mette and Ostrowski, Sisse Rye and S{\ae}kmose, Susanne and S{\o}rensen, Erik and Thorsteinsdottir, Unnur and Brun, Mie Topholm and Ullum, Henrik and Werge, Thomas and Thorleifsson, Gudmar and Jonsson, Frosti and Melsted, Pall and Jonsdottir, Ingileif and Rafnar, Thorunn and Holm, Hilma and Stefansson, Hreinn and Saemundsdottir, Jona and Gudbjartsson, Daniel F. and Magnusson, Olafur T. and Masson, Gisli and Thorsteinsdottir, Unnur and Helgason, Agnar and Jonsson, Hakon and Sulem, Patrick and Stefansson, Kari},
  year = 2022,
  journal = {Nature},
  volume = {607},
  number = {7920},
  pages = {732--740},
  issn = {0028-0836},
  doi = {10.1038/s41586-022-04965-x},
  abstract = {Detailed knowledge of how diversity in the sequence of the human genome affects phenotypic diversity depends on a comprehensive and reliable characterization of both sequences and phenotypic variation. Over the past decade, insights into this relationship have been obtained from whole-exome sequencing or whole-genome sequencing of large cohorts with rich phenotypic data1,2. Here we describe the analysis of whole-genome sequencing of 150,119 individuals from the UK Biobank3. This constitutes a set of high-quality variants, including 585,040,410 single-nucleotide polymorphisms, representing 7.0\% of all possible human single-nucleotide polymorphisms, and 58,707,036 indels. This large set of variants allows us to characterize selection based on sequence variation within a population through a depletion rank score of windows along the genome. Depletion rank analysis shows that coding exons represent a small fraction of regions in the genome subject to strong sequence conservation. We define three cohorts within the UK Biobank: a large British Irish cohort, a smaller African cohort and a South Asian cohort. A haplotype reference panel is provided that allows reliable imputation of most variants carried by three or more sequenced individuals. We identified 895,055 structural variants and 2,536,688 microsatellites, groups of variants typically excluded from large-scale whole-genome sequencing studies. Using this formidable new resource, we provide several examples of trait associations for rare variants with large effects not found previously through studies based on whole-exome sequencing and/or imputation. To measure selection on variants, whole-genome sequencing of approximately 150,000 individuals from the UK Biobank is used to rank sequence variants by their level of depletion.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC9329122},
  pmid = {35859178},
  keywords = {neurometabolism}
}

@book{irq,
  title = {Envisioning a Transformed Clinical Trials Enterprise for 2030},
  author = {{National Academies of Sciences Engineering and Medicine}},
  year = 2022,
  publisher = {{National Academies of Sciences, Engineering, and Medicine}},
  doi = {10.17226/26349},
  isbn = {978-0-309-26928-5},
  keywords = {\research methods}
}

@article{ismond2024,
  title = {An Open Label Feasibility Study of a Nutrition and Exercise App-Based Solution in Cirrhosis},
  author = {Ismond, Kathleen P and Cruz, Christofer and {Limon-Miro}, Ana Teresa and Low, Gavin and Prado, Carla M and Spence, John C and Raman, Maitreyi and McNeely, Margaret L and Tandon, Puneeta},
  year = 2024,
  month = feb,
  journal = {Canadian Liver Journal},
  volume = {7},
  number = {1},
  pages = {5--15},
  issn = {2561-4444},
  doi = {10.3138/canlivj-2023-0011},
  urldate = {2025-12-26},
  abstract = {Background:               Nutrition and exercise are the mainstay of therapy for the prevention and treatment of frailty in cirrhosis. This pilot study assessed feasibility of the online delivery of an app-based semi-supervised nutrition and exercise intervention in this population.                                         Methods:               The 11-week pilot recruited adults with cirrhosis who owned internet-connected devices. Patients were encouraged to participate in exercise sessions 3\texttimes{} per week including a combination of online group exercise (weekly) and home-based follow-along exercise (biweekly). They also participated in group nutrition classes (five sessions) and one-to-one exercise and nutrition check-ins delivered through the app. Primary outcome measures pertained to program feasibility: recruitment, retention, adherence, and satisfaction. Exploratory measures included physical performance (liver frailty index [LFI], 6-minute walk test [6MWT]), health behaviour domains, and quality of life.                                         Results:               Twenty three patients completed baseline measures. Of these, 18 (72\%) completed end of study measures (mean MELD-Na, 9.2; female, 44.4\%). Over 70\% of participants fulfilled 75\% or more of the feasibility criteria. Satisfaction with the program was high (mean, 89\%). Exercise program modifications were required for 17 patients to accommodate health events or abilities. Exploratory evaluation showed improvement in the LFI and the 6MWT by -0.58-units (95\% CI: -0.91 to -0.25) and 46.0 m (95\% CI: 22.7--69.3) respectively without changes in quality of life or health behaviour domains.                                         Conclusions:               Outcomes demonstrate feasibility of the app-based delivery of programming with promising exploratory impact on efficacy for physical performance. Findings can guide the design of a large-scale app-based randomized controlled trials in cirrhosis.},
  langid = {english},
  file = {/Users/lawrencericher/Zotero/storage/SUI3XWJU/Ismond et al. - 2024 - An open label feasibility study of a nutrition and exercise app-based solution in cirrhosis.pdf}
}

@article{jin2024matching-1d5,
  title = {Matching Patients to Clinical Trials with Large Language Models},
  author = {Jin, Qiao and Wang, Zifeng and Floudas, Charalampos S. and Chen, Fangyuan and Gong, Changlin and {Bracken-Clarke}, Dara and Xue, Elisabetta and Yang, Yifan and Sun, Jimeng and Lu, Zhiyong},
  year = 2024,
  journal = {Nature Communications},
  volume = {15},
  number = {1},
  eprint = {2307.15051},
  pages = {9074},
  doi = {10.1038/s41467-024-53081-z},
  abstract = {Patient recruitment is challenging for clinical trials. We introduce TrialGPT, an end-to-end framework for zero-shot patient-to-trial matching with large language models. TrialGPT comprises three modules: it first performs large-scale filtering to retrieve candidate trials (TrialGPT-Retrieval); then predicts criterion-level patient eligibility (TrialGPT-Matching); and finally generates trial-level scores (TrialGPT-Ranking). We evaluate TrialGPT on three cohorts of 183 synthetic patients with over 75,000 trial annotations. TrialGPT-Retrieval can recall over 90\% of relevant trials using less than 6\% of the initial collection. Manual evaluations on 1015 patient-criterion pairs show that TrialGPT-Matching achieves an accuracy of 87.3\% with faithful explanations, close to the expert performance. The TrialGPT-Ranking scores are highly correlated with human judgments and outperform the best-competing models by 43.8\% in ranking and excluding trials. Furthermore, our user study reveals that TrialGPT can reduce the screening time by 42.6\% in patient recruitment. Overall, these results have demonstrated promising opportunities for patient-to-trial matching with TrialGPT. Patient recruitment is challenging for clinical trials. Here, the authors introduce TrialGPT, an end-to-end framework for zero-shot patient-to-trial matching with large language models.},
  pmcid = {PMC11574183},
  pmid = {39557832},
  keywords = {CTAP}
}

@article{kantor2024,
  title = {Machine Learning and Natural Language Processing in Clinical Trial Eligibility Criteria Parsing: A Scoping Review},
  shorttitle = {Machine Learning and Natural Language Processing in Clinical Trial Eligibility Criteria Parsing},
  author = {Kantor, Klaudia and Morzy, Miko{\l}aj},
  year = 2024,
  month = oct,
  journal = {Drug Discovery Today},
  volume = {29},
  number = {10},
  pages = {104139},
  issn = {13596446},
  doi = {10.1016/j.drudis.2024.104139},
  urldate = {2025-12-26},
  langid = {english}
}

@article{kehl2024identifying-42f,
  title = {Identifying Oncology Clinical Trial Candidates Using Artificial Intelligence Predictions of Treatment Change: A Pilot Implementation Study},
  author = {Kehl, Kenneth L. and Mazor, Tali and Trukhanov, Pavel and Lindsay, James and Galvin, Matthew R. and Farhat, Karim S. and McClure, Emily and Giordano, Antonio and Gandhi, Leena and Schrag, Deborah and Hassett, Michael J. and Cerami, Ethan},
  year = 2024,
  journal = {JCO Precision Oncology},
  volume = {8},
  number = {8},
  pages = {e2300507},
  issn = {2473-4284},
  doi = {10.1200/po.23.00507},
  abstract = {Precision oncology clinical trials often struggle to accrue, partly because it is difficult to find potentially eligible patients at moments when they need new treatment. We piloted deployment of artificial intelligence tools to identify such patients at a large academic cancer center. Neural networks that process radiology reports to identify patients likely to start new systemic therapy were applied prospectively for patients with solid tumors that had undergone next-generation sequencing at our center. Model output was linked to the MatchMiner tool, which matches patients to trials using tumor genomics. Reports listing genomically matched patients, sorted by probability of treatment change, were provided weekly to an oncology nurse navigator (ONN) coordinating recruitment to nine early-phase trials. The ONN contacted treating oncologists when patients likely to change treatment appeared potentially trial-eligible. Within weekly reports to the ONN, 60,199 patient-trial matches were generated for 2,150 patients on the basis of genomics alone. Of these, 3,168 patient-trial matches (5\%) corresponding to 525 patients were flagged for ONN review by our model, representing a 95\% reduction in review compared with manual review of all patient-trial matches weekly. After ONN review for potential eligibility, treating oncologists for 74 patients were contacted. Common reasons for not contacting treating oncologists included cases where patients had already decided to continue current treatment (21\%); the trial had no slots (14\%); or the patient was ineligible on ONN review (12\%). Of 74 patients whose oncologists were contacted, 10 (14\%) had a consult regarding a trial and five (7\%) enrolled. This approach facilitated identification of potential patients for clinical trials in real time, but further work to improve accrual must address the many other barriers to trial enrollment in precision oncology research.},
  langid = {english},
  pmcid = {PMC10965204},
  pmid = {38513166}
}

@article{kopylova2022,
  title = {Electronic Medical Records and Biobanking},
  author = {Kopylova, O V and Ershova, A I and Efimova, I A and Blokhina, A V and Limonova, A S and Borisova, A L and Pokrovskaya, M S and Drapkina, O M},
  year = 2022,
  journal = {Cardiovascular Therapy and Prevention},
  volume = {21},
  number = {11},
  pages = {3425},
  issn = {1728-8800},
  doi = {10.15829/1728-8800-2022-3425},
  abstract = {Biosample preservation for future research is a fundamental component of translational medicine. At the same time, the value of stored biosamples is largely determined by the presence of related clinical data and other information. Electronic medical records are a unique source of a large amount of information received over a long period of time. In this regard, genetic and other types of data obtained from the biosample analysis can be associated with phenotypic and other types of information stored in electronic medical records, which pushes the boundaries in large-scale genetic research and improves healthcare. The aim of this review was to analyze the literature on the potential of combining electronic medical records and biobank databases in research and clinical practice.},
  keywords = {biobanking,emr,research informatics,research methods}
}

@article{lee2024,
  title = {Optimizing {{Clinical Trial Eligibility Design Using Natural Language Processing Models}} and {{Real-World Data}}: {{Algorithm Development}} and {{Validation}}},
  shorttitle = {Optimizing {{Clinical Trial Eligibility Design Using Natural Language Processing Models}} and {{Real-World Data}}},
  author = {Lee, Kyeryoung and Liu, Zongzhi and Mai, Yun and Jun, Tomi and Ma, Meng and Wang, Tongyu and Ai, Lei and Calay, Ediz and Oh, William and Stolovitzky, Gustavo and Schadt, Eric and Wang, Xiaoyan},
  year = 2024,
  month = jul,
  journal = {JMIR AI},
  volume = {3},
  pages = {e50800},
  issn = {2817-1705},
  doi = {10.2196/50800},
  urldate = {2025-12-26},
  abstract = {Background               Clinical trials are vital for developing new therapies but can also delay drug development. Efficient trial data management, optimized trial protocol, and accurate patient identification are critical for reducing trial timelines. Natural language processing (NLP) has the potential to achieve these objectives.                                         Objective               This study aims to assess the feasibility of using data-driven approaches to optimize clinical trial protocol design and identify eligible patients. This involves creating a comprehensive eligibility criteria knowledge base integrated within electronic health records using deep learning--based NLP techniques.                                         Methods               We obtained data of 3281 industry-sponsored phase 2 or 3 interventional clinical trials recruiting patients with non--small cell lung cancer, prostate cancer, breast cancer, multiple myeloma, ulcerative colitis, and Crohn disease from ClinicalTrials.gov, spanning the period between 2013 and 2020. A customized bidirectional long short-term memory-- and conditional random field--based NLP pipeline was used to extract all eligibility criteria attributes and convert hypernym concepts into computable hyponyms along with their corresponding values. To illustrate the simulation of clinical trial design for optimization purposes, we selected a subset of patients with non--small cell lung cancer (n=2775), curated from the Mount Sinai Health System, as a pilot study.                                         Results               We manually annotated the clinical trial eligibility corpus (485/3281, 14.78\% trials) and constructed an eligibility criteria--specific ontology. Our customized NLP pipeline, developed based on the eligibility criteria--specific ontology that we created through manual annotation, achieved high precision (0.91, range 0.67-1.00) and recall (0.79, range 0.50-1) scores, as well as a high F1-score (0.83, range 0.67-1), enabling the efficient extraction of granular criteria entities and relevant attributes from 3281 clinical trials. A standardized eligibility criteria knowledge base, compatible with electronic health records, was developed by transforming hypernym concepts into machine-interpretable hyponyms along with their corresponding values. In addition, an interface prototype demonstrated the practicality of leveraging real-world data for optimizing clinical trial protocols and identifying eligible patients.                                         Conclusions               Our customized NLP pipeline successfully generated a standardized eligibility criteria knowledge base by transforming hypernym criteria into machine-readable hyponyms along with their corresponding values. A prototype interface integrating real-world patient information allows us to assess the impact of each eligibility criterion on the number of patients eligible for the trial. Leveraging NLP and real-world data in a data-driven approach holds promise for streamlining the overall clinical trial process, optimizing processes, and improving efficiency in patient identification.},
  langid = {english}
}

@article{li2021,
  title = {Artificial Intelligence for Screening Chinese Electronic Medical Record and Biobank Information},
  author = {Li, Xiaoqing and Han, Jiang and Zhang, Shaodian and Chen, Ken and Zhao, Liebin and He, Yi and Liu, Shijian},
  year = 2021,
  journal = {Biopreservation and Biobanking},
  volume = {19},
  number = {5},
  pages = {386--393},
  issn = {1947-5535},
  doi = {10.1089/bio.2020.0151},
  abstract = {Objective: To establish a structured and integrated platform of clinical data and biobank data, and a client to retrieve these data. Study Design: Initially, the hospital information system (HIS) and biobank information system (BIS) were integrated through the patients' ID numbers. Then, natural language processing (NLP) was used to process the integrated unstructured clinical information. A query interface was designed for this system, which enabled researchers to retrieve clinical or biobank data. Finally, several queries were listed and manually checked to test the retrieval performance of the system. Results: The construction of the biobank screening system (BSS) was completed, and the data were structured. The BSS took an average of 2 seconds to perform a search for target patients/samples. The retrieval results were consistent with the HIS and BIS. For complex queries, we manually checked the retrieved patients/samples, and the system's accuracy was 100\%. Conclusion: This NLP-based system improved biological sample screening and using of clinical data. We will continue to improve this system, enhance resource sharing, and promote the development of translational medicine.},
  pmid = {34042506},
  keywords = {AI,biobanking,emr}
}

@article{lu2024artificial-5e0,
  title = {Artificial Intelligence Tools for Optimising Recruitment and Retention in Clinical Trials: A Scoping Review Protocol},
  author = {Lu, Xiaoran and Chen, Mingan and Lu, Zhuolin and Shi, Xiaoting and Liang, Lu},
  year = 2024,
  journal = {BMJ Open},
  volume = {14},
  number = {3},
  pages = {e080032},
  issn = {2044-6055},
  doi = {10.1136/bmjopen-2023-080032},
  abstract = {Introduction In recent years, the influence of artificial intelligence technology on clinical trials has been steadily increasing. It has brought about significant improvements in the efficiency and cost reduction of clinical trials. The objective of this scoping review is to systematically map, describe and summarise the current utilisation of artificial intelligence in recruitment and retention process of clinical trials that has been reported in research. Additionally, the review aims to identify benefits and drawbacks, as well as barriers and facilitators associated with the application of artificial intelligence in optimising recruitment and retention in clinical trials. The findings of this review will provide insights and recommendations for future development of artificial intelligence in the context of clinical trials. Methods and analysis The review of relevant literature will follow the methodological framework for scoping studies provided by the Joanna Briggs Institute. A comprehensive electronic search will be conducted using the search strategy developed by the authors. Leading medical and computer science databases such as PubMed, Embase, Scopus, IEEE Xplore and Web of Science Core Collection will be searched. The search will encompass analytical observational studies, descriptive observational studies, experimental and quasi-experimental studies published in all languages, without any time limitations, which use artificial intelligence tools in the recruitment and retention process of clinical trials. The review team will screen the identified studies and import them into a dedicated electronic library specifically created for this review. Data extraction will be performed using a data charting table. Ethics and dissemination Secondary data will be attained in this scoping review; therefore, no ethical approval is required. The results of the final review will be published in a peer-reviewed journal. It is expected that results will inform future artificial intelligence and clinical trials research.},
  langid = {english}
}

@article{lu2024artificial-75a,
  title = {Artificial Intelligence for Optimizing Recruitment and Retention in Clinical Trials: A Scoping Review},
  author = {Lu, Xiaoran and Yang, Chen and Liang, Lu and Hu, Guanyu and Zhong, Ziyi and Jiang, Zihao},
  year = 2024,
  journal = {Journal of the American Medical Informatics Association},
  volume = {31},
  number = {11},
  pages = {2749--2759},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocae243},
  abstract = {Abstract Objective The objective of our research is to conduct a comprehensive review that aims to systematically map, describe, and summarize the current utilization of artificial intelligence (AI) in the recruitment and retention of participants in clinical trials. Materials and Methods A comprehensive electronic search was conducted using the search strategy developed by the authors. The search encompassed research published in English, without any time limitations, which utilizes AI in the recruitment process of clinical trials. Data extraction was performed using a data charting table, which included publication details, study design, and specific outcomes/results. Results The search yielded 5731 articles, of which 51 were included. All the studies were designed specifically for optimizing recruitment in clinical trials and were published between 2004 and 2023. Oncology was the most covered clinical area. Applying AI to recruitment in clinical trials has demonstrated several positive outcomes, such as increasing efficiency, cost savings, improving recruitment, accuracy, patient satisfaction, and creating user-friendly interfaces. It also raises various technical and ethical issues, such as limited quantity and quality of sample size, privacy, data security, transparency, discrimination, and selection bias. Discussion and Conclusion While AI holds promise for optimizing recruitment in clinical trials, its effectiveness requires further validation. Future research should focus on using valid and standardized outcome measures, methodologically improving the rigor of the research carried out.},
  langid = {english}
}

@article{lyon2016,
  title = {Research-{{Focused Isolation}} of {{Human Islets From Donors With}} and {{Without Diabetes}} at the {{Alberta Diabetes Institute IsletCore}}},
  author = {Lyon, James and Manning Fox, Jocelyn E. and Spigelman, Aliya F. and Kim, Ryekjang and Smith, Nancy and O'Gorman, Doug and Kin, Tatsuya and Shapiro, A. M. James and Rajotte, Raymond V. and MacDonald, Patrick E.},
  year = 2016,
  month = feb,
  journal = {Endocrinology},
  volume = {157},
  number = {2},
  pages = {560--569},
  issn = {0013-7227, 1945-7170},
  doi = {10.1210/en.2015-1562},
  urldate = {2025-12-26},
  abstract = {Abstract             Recent years have seen an increased focus on human islet biology, and exciting findings in the stem cell and genomic arenas highlight the need to define the key features of mature human islets and {$\beta$}-cells. Donor and organ procurement parameters impact human islet yield, although for research purposes islet yield may be secondary in importance to islet function. We examined the feasibility of a research-only human islet isolation, distribution, and biobanking program and whether key criteria such as cold ischemia time (CIT) and metabolic status may be relaxed and still allow successful research-focused isolations, including from donors with type 1 diabetes and type 2 diabetes. Through 142 isolations over approximately 5 years, we confirm that CIT and glycated hemoglobin each have a weak negative impacts on isolation purity and yield, and extending CIT beyond the typical clinical isolation cutoff of 12 hours (to {$\geq$} 18 h) had only a modest impact on islet function. Age and glycated hemoglobin/type 2 diabetes status negatively impacted secretory function; however, these and other biological (sex, body mass index) and procurement/isolation variables (CIT, time in culture) appear to make only a small contribution to the heterogeneity of human islet function. This work demonstrates the feasibility of extending acceptable CIT for research-focused human islet isolation and highlights the biological variation in function of human islets from donors with and without diabetes.},
  langid = {english}
}

@article{malone2020,
  title = {Molecular Profiling for Precision Cancer Therapies},
  author = {Malone, Eoghan R. and Oliva, Marc and Sabatini, Peter J. B. and Stockley, Tracy L. and Siu, Lillian L.},
  year = 2020,
  month = dec,
  journal = {Genome Medicine},
  volume = {12},
  number = {1},
  pages = {8},
  issn = {1756-994X},
  doi = {10.1186/s13073-019-0703-1},
  urldate = {2025-12-29},
  abstract = {Abstract             The number of druggable tumor-specific molecular aberrations has grown substantially in the past decade, with a significant survival benefit obtained from biomarker matching therapies in several cancer types. Molecular pathology has therefore become fundamental not only to inform on tumor diagnosis and prognosis but also to drive therapeutic decisions in daily practice. The introduction of next-generation sequencing technologies and the rising number of large-scale tumor molecular profiling programs across institutions worldwide have revolutionized the field of precision oncology. As comprehensive genomic analyses become increasingly available in both clinical and research settings, healthcare professionals are faced with the complex tasks of result interpretation and translation. This review summarizes the current and upcoming approaches to implement precision cancer medicine, highlighting the challenges and potential solutions to facilitate the interpretation and to maximize the clinical utility of molecular profiling results. We describe novel molecular characterization strategies beyond tumor DNA sequencing, such as transcriptomics, immunophenotyping, epigenetic profiling, and single-cell analyses. We also review current and potential applications of liquid biopsies to evaluate blood-based biomarkers, such as circulating tumor cells and circulating nucleic acids. Last, lessons learned from the existing limitations of genotype-derived therapies provide insights into ways to expand precision medicine beyond genomics.},
  langid = {english},
  file = {/Users/lawrencericher/Zotero/storage/JRX7HU43/Malone et al. - 2020 - Molecular profiling for precision cancer therapies.pdf}
}

@article{noauthornoyearmandate-009,
  title = {Mandate Letter - Technology and Innovation}
}

@article{palmirotta2013,
  title = {Establishment of a Biorepository for Migraine Research: The Experience of {{Interinstitutional Multidisciplinary BioBank}} ({{BioBIM}}).},
  author = {Palmirotta, Raffaele and Barbanti, Piero and Ludovici, Giorgia and Egeo, Gabriella and Aurilia, Cinzia and Fofi, Luisa and Marchis, Maria Laura De and Spila, Antonella and Ferroni, Patrizia and {Della-Morte}, David and Guadagni, Fiorella},
  year = 2013,
  journal = {Neurological sciences : official journal of the Italian Neurological Society and of the Italian Society of Clinical Neurophysiology},
  volume = {34},
  pages = {1659--1663},
  abstract = {The development of Biobanks and recent advances in molecular biology have enhanced the possibility to accelerate translational research studies. The Interinstitutional Multidisciplinary BioBank (BioBIM) is organized in a large healthy donors collection and pathology-based biobanks with the aim to provide a service for development of interdisciplinary studies. A new pathology-based biobank has been organized to specifically collect biospecimen from patients affected by migraine, with the final goal to centralize data, collect blood, plasma, serum, DNA and RNA of patients with this disease. The BioBIM is fully equipped for the automation of sampling/processing, storage and tracking of biospecimens. Standard Operating Procedures have been developed for processing and storage phases as well as archive of clinical data. The availability of biospecimens and clinical data will constitute a resource for various research projects.},
  rating = {0},
  keywords = {biobanking,migraine}
}

@article{papez2022,
  title = {Transforming and Evaluating the {{UK Biobank}} to the {{OMOP Common Data Model}} for {{COVID-19}} Research and Beyond},
  author = {Papez, Vaclav and Moinat, Maxim and Voss, Erica A and Bazakou, Sofia and Van Winzum, Anne and Peviani, Alessia and Payralbe, Stefan and Lara, Elena Garcia and Kallfelz, Michael and Asselbergs, Folkert W and {Prieto-Alhambra}, Daniel and Dobson, Richard J B and Denaxas, Spiros},
  year = 2022,
  month = dec,
  journal = {Journal of the American Medical Informatics Association},
  volume = {30},
  number = {1},
  pages = {103--111},
  issn = {1067-5027, 1527-974X},
  doi = {10.1093/jamia/ocac203},
  urldate = {2025-12-26},
  abstract = {Abstract                            Objective               The coronavirus disease 2019 (COVID-19) pandemic has demonstrated the value of real-world data for public health research. International federated analyses are crucial for informing policy makers. Common data models (CDMs) are critical for enabling these studies to be performed efficiently. Our objective was to convert the UK Biobank, a study of 500{$\mkern1mu$}000 participants with rich genetic and phenotypic data to the Observational Medical Outcomes Partnership (OMOP) CDM.                                         Materials and Methods               We converted UK Biobank data to OMOP CDM v. 5.3. We transformedparticipant research data on diseases collected at recruitment and electronic health records (EHRs) from primary care, hospitalizations, cancer registrations, and mortality from providers in England, Scotland, and Wales. We performed syntactic and semantic validations and compared comorbidities and risk factors between source and transformed data.                                         Results               We identified 502{$\mkern1mu$}505 participants (3086 with COVID-19) and transformed 690 fields (1{$\mkern1mu$}373{$\mkern1mu$}239{$\mkern1mu$}555 rows) to the OMOP CDM using 8 different controlled clinical terminologies and bespoke mappings. Specifically, we transformed self-reported noncancer illnesses 946{$\mkern1mu$}053 (83.91\% of all source entries), cancers 37{$\mkern1mu$}802 (70.81\%), medications 1{$\mkern1mu$}218{$\mkern1mu$}935 (88.25\%), and prescriptions 864{$\mkern1mu$}788 (86.96\%). In EHR, we transformed 13{$\mkern1mu$}028{$\mkern1mu$}182 (99.95\%) hospital diagnoses, 6{$\mkern1mu$}465{$\mkern1mu$}399 (89.2\%) procedures, 337{$\mkern1mu$}896{$\mkern1mu$}333 primary care diagnoses (CTV3, SNOMED-CT), 139{$\mkern1mu$}966{$\mkern1mu$}587 (98.74\%) prescriptions (dm+d) and 77{$\mkern1mu$}127 (99.95\%) deaths (ICD-10). We observed good concordance across demographic, risk factor, and comorbidity factors between source and transformed data.                                         Discussion and Conclusion               Our study demonstrated that the OMOP CDM can be successfully leveraged to harmonize complex large-scale biobanked studies combining rich multimodal phenotypic data. Our study uncovered several challenges when transforming data from questionnaires to the OMOP CDM which require further research. The transformed UK Biobank resource is a valuable tool that can enable federated research, like COVID-19 studies.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/lawrencericher/Zotero/storage/Z4DFKYFH/Papez et al. - 2022 - Transforming and evaluating the UK Biobank to the OMOP Common Data Model for COVID-19 research and b.pdf}
}

@article{prictor2018,
  title = {Equitable Participation in Biobanks: {{The}} Risks and Benefits of a ``Dynamic Consent'' Approach},
  author = {Prictor, Megan and Teare, Harriet J. A. and Kaye, Jane},
  year = 2018,
  journal = {Frontiers in Public Health},
  volume = {6},
  pages = {253},
  issn = {2296-2565},
  doi = {10.3389/fpubh.2018.00253},
  abstract = {Participation in biobanks tends to favor certain groups---white, middle-class, more highly-educated---often to the exclusion of others, such as indigenous people, the socially-disadvantaged and the culturally and linguistically diverse. Barriers to participation, which include age, location, cultural sensitivities around human tissue, and issues of literacy and language, can influence the diversity of samples found in biobanks. This has implications for the generalizability of research findings from biobanks being able to be translated into the clinic. Dynamic Consent, which is a digital decision-support tool, could improve participants' recruitment to, and engagement with, biobanks over time and help to overcome some of the barriers to participation. However, there are also risks that it may deepen the ``digital divide'' by favoring those with knowledge and access to digital technologies, with the potential to decrease participant engagement in research. When applying a Dynamic Consent approach in biobanking, researchers should give particular attention to adaptations that can improve participant inclusivity, and evaluate the tool empirically, with a focus on equity-relevant outcome measures. This may help biobanks to fulfill their promise of enabling translational research that is relevant to all.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC6133951},
  pmid = {30234093},
  keywords = {biobanking,dynamic consent}
}

@misc{research2024integration-002,
  title = {{{INTEGRATION OF ARTIFICIAL INTELLIGENCE IN ADAPTIVE TRIAL DESIGNS}}: {{ENHANCING EFFICIENCY AND PATIENT-CENTRIC OUTCOMES}}},
  author = {Research, Pharm. D, Quality Assurance Associate. and Research, Pharm. D, Quality Assurance Associate. and Coordinator., MS Applied Clinical Research Pharm. D, Clinical Research},
  year = 2024,
  publisher = {International Journal Of Advanced Research},
  abstract = {Background: Integrating artificial intelligence (AI) into adaptive trial designs represents a transformative approach in clinical research, promising enhanced efficiency and accuracy in trial outcomes. This study aims to systematically review the current landscape of AI applications in adaptive clinical trial designs. Methods: A comprehensive search was conducted across multiple databases, resulting in 6177 records initially identified. After removing duplicates and ineligible records, 1476 studies were screened. Following rigorous screening and eligibility assessment, 45 studies were included in the final review. Inclusion criteria focused on peer-reviewed articles, systematic reviews, and clinical trials discussing the role of AI in adaptive trial designs. In contrast, exclusion criteria eliminated non-relevant and low-quality studies. Results: The selected studies demonstrate that AI significantly improves adaptive trial designs through advanced data analytics, predictive modelling, and real-time decision-making. AIs integration facilitates dynamic randomization, optimised dosing strategies, and efficient patient recruitment, thereby enhancing the overall effectiveness of clinical trials. Conclusion: AI integration in adaptive trial designs offers substantial benefits regarding trial efficiency, precision, and patient outcomes. Despite existing challenges such as data quality, ethical considerations, and regulatory requirements, the findings underscore the potential for AI to revolutionise clinical trials. Future research should address these challenges to harness AIs capabilities in adaptive trial designs fully.}
}

@article{saady2025implementation-4b4,
  title = {Implementation of Artificial Intelligence Approaches in Oncology Clinical Trials: {{A}} Systematic Review},
  author = {Saady, Marwa and Eissa, Mahmoud and Yacoub, Ahmed S. and Hamed, Ahmed B. and Azzazy, Hassan Mohamed El-Said},
  year = 2025,
  journal = {Artificial Intelligence in Medicine},
  volume = {161},
  pages = {103066},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2025.103066},
  abstract = {INTRODUCTION There is a growing interest in leveraging artificial intelligence (AI) technologies to enhance various aspects of clinical trials. The goal of this systematic review is to assess the impact of implementing AI approaches on different aspects of oncology clinical trials. METHODS Pertinent keywords were used to find relevant articles published in PubMed, Scopus, and Google Scholar databases, which described the clinical application of AI approaches. A quality evaluation utilizing a customized checklist specifically adapted was conducted. This study is registered with PROSPERO (CRD42024537153). RESULTS Out of the identified 2833 studies, 72 studies satisfied the inclusion criteria. Clinical Trial Enrollment \& Eligibility were among the most commonly studied clinical trial aspects with 30 papers. The prediction of outcomes was covered in 25 studies of which 15 addressed the prediction of patients' survival and 10 addressed the prediction of drug outcomes. The trial design was studied in 10 articles. Three studies addressed each of the personalized treatments and decision-making, while one addressed data management. The results demonstrate using AI in cancer clinical trials has the potential to increase clinical trial enrollment, predict clinical outcomes, improve trial design, enhance personalized treatments, and increase concordance in decision-making. Additionally, automating some areas and tasks, clinical trials were made more efficient, and human error was minimized. Nevertheless, concerns and restrictions related to the application of AI in clinical studies are also noted. CONCLUSION AI tools have the potential to revolutionize the design, enrollment rate, and outcome prediction of oncology clinical trials. Copyright \copyright{} 2025 Elsevier B.V. All rights reserved.},
  langid = {english}
}

@article{saginur2022,
  title = {No Time for Complacency: {{The CoVaRR-Net Biobank}} Is an Essential Element of Laboratory Preparedness for Infectious Disease Outbreaks},
  author = {Saginur, Raphael and Robblee, James A and Vranjkovic, Agatha and Tamblyn, Laura and Hsu, Amy and Cooper, Curtis L and Vinh, Donald C and Langlois, Marc-Andr{\'e} and Crawley, Angela M},
  year = 2022,
  journal = {Journal of the Association of Medical Microbiology and Infectious Disease Canada},
  volume = {8},
  number = {1},
  pages = {75--84},
  issn = {2371-0888},
  doi = {10.3138/jammi-2022-0009},
  abstract = {The SARS-CoV-2 pandemic highlighted the need for rapid, collaborative, and population-centric research to define health impact, develop health care policies and establish reliable diagnostic and surveillance tests. Critical for these objectives were in-depth clinical data collected in standardized fashion and large numbers of various types of human samples prior and post-viral encounter. As the pandemic evolved with the emergence of new variants of concern (VOCs), access to samples and data from infected and vaccinated individuals were needed to monitor immune durability, the possibility of increased transmissibility and virulence, and vaccine protection against new and emerging VOCs. Therefore, essential to the pandemic response is a strong laboratory and data research component, supported by effective biobanking and data sharing. Critically important to the speed of the research response is the rapid access to biobanked samples. To address critical challenges brought to light by the pandemic, the Coronavirus Variants Rapid Response Network (CoVaRR-Net), funded by the Canadian Institutes of Health Research, was established to coordinate research efforts to provide rapid evidence-based responses to emerging VOCs. The purpose of this paper is to introduce the CoVaRR-Net Biobank and define its contribution to pandemic preparedness. La pand\'emie de SRAS-CoV-2 a fait ressortir la n\'ecessit\'e de r\'ealiser des recherches rapides, coop\'eratives et populationnelles pour en d\'efinir les effets sur la sant\'e, promulguer des politiques sanitaires et \'etablir des tests diagnostiques et des tests de surveillance fiables. Pour r\'ealiser ces objectifs, il \'etait essentiel de colliger des donn\'ees cliniques approfondies d'une mani\`ere standardis\'ee et d'amasser un grand nombre de divers types d'\'echantillons humains avant et apr\`es le contact viral. Lorsque la pand\'emie a \'evolu\'e par l'\'emergence de nouveaux variants pr\'eoccupants (VOC), il est devenu n\'ecessaire d'acc\'eder \`a des \'echantillons et \`a des donn\'ees de personnes infect\'ees et vaccin\'ees pour surveiller la durabilit\'e de l'immunit\'e, la possibilit\'e d'une transmissibilit\'e et d'une virulence accrues et la protection conf\'er\'ee par les vaccins contre les VOC nouveaux et \'emergents. Ainsi, il est essentiel de disposer d'un vigoureux volet de recherches de laboratoire et de recherches \`a partir de donn\'ees pour r\'epondre \`a la pand\'emie, soutenu par une mise en biobanque et un partage des donn\'ees efficaces. Pour assurer une r\'eponse rapide par la recherche, il est tout aussi important d'acc\'eder rapidement aux \'echantillons mis en biobanque. Afin de relever les d\'efis cruciaux soulev\'es par la pand\'emie, le Coronavirus Variants Rapid Response Network (r\'eseau de r\'eponse rapide aux variants du coronavirus; CoVaRR-Net), financ\'e par les Instituts de recherche en sant\'e du Canada, a \'et\'e cr\'e\'e pour coordonner les efforts de recherche afin de fournir des r\'eponses rapides fond\'ees sur des donn\'ees probantes aux VOC en \'emergence. Le pr\'esent article vise \`a pr\'esenter la Biobanque CoVaRR-Net et \`a en d\'efinir la contribution \`a la pr\'eparation aux pand\'emies.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmcid = {PMC10052913},
  pmid = {37008580},
  keywords = {biobanking}
}

@article{sudlow2015,
  title = {{{UK Biobank}}: {{An Open Access Resource}} for {{Identifying}} the {{Causes}} of a {{Wide Range}} of {{Complex Diseases}} of {{Middle}} and {{Old Age}}},
  shorttitle = {{{UK Biobank}}},
  author = {Sudlow, Cathie and Gallacher, John and Allen, Naomi and Beral, Valerie and Burton, Paul and Danesh, John and Downey, Paul and Elliott, Paul and Green, Jane and Landray, Martin and Liu, Bette and Matthews, Paul and Ong, Giok and Pell, Jill and Silman, Alan and Young, Alan and Sprosen, Tim and Peakman, Tim and Collins, Rory},
  year = 2015,
  month = mar,
  journal = {PLOS Medicine},
  volume = {12},
  number = {3},
  pages = {e1001779},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1001779},
  urldate = {2025-12-29},
  langid = {english},
  file = {/Users/lawrencericher/Zotero/storage/MAC9WSQ2/Sudlow et al. - 2015 - UK Biobank An Open Access Resource for Identifying the Causes of a Wide Range of Complex Diseases o.pdf}
}

@article{szustakowski2021,
  title = {Advancing Human Genetics Research and Drug Discovery through Exome Sequencing of the {{UK Biobank}}},
  author = {Szustakowski, Joseph D and Balasubramanian, Suganthi and Kvikstad, Erika and Khalid, Shareef and Bronson, Paola G and Sasson, Ariella and Wong, Emily and Liu, Daren and Davis, J Wade and Haefliger, Carolina and Loomis, A Katrina and Mikkilineni, Rajesh and Noh, Hyun Ji and Wadhawan, Samir and Bai, Xiaodong and Hawes, Alicia and Krasheninina, Olga and Ulloa, Ricardo and Lopez, Alex E and Smith, Erin N and Waring, Jeffrey F and Whelan, Christopher D and Tsai, Ellen A and Overton, John D and Salerno, William J and Jacob, Howard and Szalma, Sandor and Runz, Heiko and Hinkle, Gregory and Nioi, Paul and Petrovski, Slav{\'e} and Miller, Melissa R and Baras, Aris and Mitnaul, Lyndon J and Reid, Jeffrey G and Team, UKB-ESC Research and Moiseyenko, Oleg and Rios, Carlos and Saha, Saurabh and Abecasis, Goncalo and Banerjee, Nilanjana and Beechert, Christina and Boutkov, Boris and Cantor, Michael and Coppola, Giovanni and Economides, Aris and Eom, Gisu and Forsythe, Caitlin and Fuller, Erin D and Gu, Zhenhua and Habegger, Lukas and Jones, Marcus B and Lanche, Rouel and Lattari, Michael and LeBlanc, Michelle and Li, Dadong and Lotta, Luca A and Manoochehri, Kia and Mansfield, Adam J and Maxwell, Evan K and Mighty, Jason and Nafde, Mrunali and O'Keeffe, Sean and Orelus, Max and Padilla, Maria Sotiropoulos and Panea, Razvan and Polanco, Tommy and Pradhan, Manasi and Rasool, Ayesha and Schleicher, Thomas D and Sharma, Deepika and Shuldiner, Alan and Staples, Jeffrey C and Hout, Cristopher V Van and Widom, Louis and Wolf, Sarah E and John, Sally and Chen, Chia-Yen and Sexton, David and Kupelian, Varant and Marshall, Eric and Swan, Timothy and Eaton, Susan and Liu, Jimmy Z and Loomis, Stephanie and Jensen, Megan and Duraisamy, Saranya and Tetrault, Jason and Merberg, David and Badola, Sunita and Reppell, Mark and Grundstad, Jason and Zheng, Xiuwen and Deaton, Aimee M and Parker, Margaret M and Ward, Lucas D and {Flynn-Carroll}, Alexander O and Austin, Caroline and March, Ruth and Pangalos, Menelas N and Platt, Adam and Snowden, Mike and Matakidou, Athena and Wasilewski, Sebastian and Wang, Quanli and Deevi, Sri and Carss, Keren and Smith, Katherine and Sogaard, Morten and Hu, Xinli and Chen, Xing and Ye, Zhan},
  year = 2021,
  journal = {Nature Genetics},
  volume = {53},
  number = {7},
  pages = {942--948},
  issn = {1061-4036},
  doi = {10.1038/s41588-021-00885-0},
  abstract = {The UK Biobank Exome Sequencing Consortium (UKB-ESC) is a private--public partnership between the UK Biobank (UKB) and eight biopharmaceutical companies that will complete the sequencing of exomes for all 500,000 UKB participants. Here, we describe the early results from 200,000 UKB participants and the features of this project that enabled its success. The biopharmaceutical industry has increasingly used human genetics to improve success in drug discovery. Recognizing the need for large-scale human genetics data, as well as the unique value of the data access and contribution terms of the UKB, the UKB-ESC was formed. As a result, exome data from 200,643 UKB enrollees are now available. These data include 10 million exonic variants---a rich resource of rare coding variation that is particularly valuable for drug discovery. The UKB-ESC precompetitive collaboration has further strengthened academic and industry ties and has provided teams with an opportunity to interact with and learn from the wider research community.},
  local-url = {file://localhost/Users/lawrencericher/Documents/Papers},
  pmid = {34183854},
  keywords = {biobanking}
}

@article{tandon2025,
  title = {Acceptability and {{Effectiveness}} of a {{Fully Web-Based Nutrition}} and {{Exercise Program}} for {{Individuals With Chronic Disease During COVID-19}}: {{Randomized Controlled Trial}}},
  shorttitle = {Acceptability and {{Effectiveness}} of a {{Fully Web-Based Nutrition}} and {{Exercise Program}} for {{Individuals With Chronic Disease During COVID-19}}},
  author = {Tandon, Puneeta and Ismond, Kathleen P and Purdy, Graeme and Cruz, Christofer and Etruw, Evelyn and Suderman, Kirsten and Hyde, Ashley and Stickland, Michael and Spence, John C and Lien, Dale C and Bhanji, Rahima and Prado, Carla M and {Miguel-Cruz}, Antonio and Joy, Anil A and Yaskina, Maryna and McNeely, Margaret L},
  year = 2025,
  month = mar,
  journal = {Journal of Medical Internet Research},
  volume = {27},
  pages = {e57537},
  issn = {1438-8871},
  doi = {10.2196/57537},
  urldate = {2025-12-26},
  abstract = {Background               In-person nutrition and exercise interventions improve physical function in chronic diseases, yet the acceptability and effectiveness of web-based delivery, especially with different levels of personnel support, require further investigation.                                         Objective               This study aims to evaluate a web-based nutrition and exercise intervention delivered entirely digitally from recruitment to trial completion.                                         Methods               A randomized controlled trial was conducted using the Heal-Me version 1 platform across 2 levels of personnel support (Light and Intensive). Eligible adults with a history of cancer, chronic lung disease, or liver or lung transplant; internet access; and prior participation in a rehabilitation program were enrolled in a fully web-based program to minimize barriers to exercise participation. Participants were randomly assigned (1:1:1) to 1 of 3 study groups. The control group received a detailed, self-directed digital nutrition and exercise guide. The Heal-Me Light group received the web-based intervention alongside dietitian and exercise specialist--led group classes. The Heal-Me Intensive group received web-based intervention, group classes, and one-to-one sessions with the dietitians and exercise specialists. All participants received a wearable activity tracker. The primary acceptability outcome was adherence to the intervention based on a priori targets. The primary effectiveness outcome was the change in Lower Extremity Functional Scale (LEFS) score. Secondary outcomes included physical function tests, which were performed and measured by videoconference. Questionnaires were used to assess well-being, quality of life, and food intake. Analyses adhered to the intention-to-treat principle.                                         Results               Of 216 participants, 202 (93.5\%) completed the intervention (mean 61, SD 11 years; female: 130/202, 64.4\%; cancer: 126/202, 62.4\%). Adherence exceeded a priori targets, with 82\% (105/128) attending {$>$}75\% of the program elements including postintervention tests. Participants rated the program as ``quite a bit'' or ``very'' useful, with similar ratings between Heal-Me Light (56/64, 88\%) and Heal-Me Intensive (51/58, 88\%) groups (P=.69). No significant differences were found for changes in LEFS scores (control: mean 0.8, SD 7.7; Heal-Me: mean 0.3, SD 6.6; P=.53). Significant benefits were found in favor of the combined Heal-Me intervention groups versus controls for change in the 2-minute step test, World Health Organization-5 Well-Being Index, Short-Form-36 general, physical health role, energy or fatigue scales, and protein intake. While the change in physical function was similar between the 2 intervention arms, the more intensive one-to-one interaction (Heal-Me Intensive) led to greater improvements in perceived nutrition self-management. No serious adverse events occurred.                                         Conclusions               The demonstrated satisfaction, adherence, and effectiveness highlight the high acceptability of a web-based, semisupervised nutrition and exercise intervention delivered entirely digitally in individuals with chronic disease. Future studies may benefit from having a baseline physical function inclusion threshold, the use of a more sensitive primary physical function measure, and a higher intensity digital exercise intervention in exercise-experienced participants.                                         Trial Registration               Clinicaltrials.gov NCT04666558; https://clinicaltrials.gov/study/NCT04666558                                         International Registered Report Identifier (IRRID)               RR2-10.1016/j.cct.2022.106791},
  langid = {english}
}

@article{teare2015,
  title = {Towards `{{Engagement}} 2.0': {{Insights}} from a Study of Dynamic Consent with Biobank Participants},
  author = {Teare, Harriet JA and Morrison, Michael and Whitley, Edgar A and Kaye, Jane},
  year = 2015,
  journal = {Digital Health},
  volume = {1},
  pages = {2055207615605644},
  issn = {2055-2076},
  doi = {10.1177/2055207615605644},
  abstract = {Web 2.0 technologies have enabled new methods of engagement, moving from static mono-directional sources of information to interactive user-led experiences. Use of Web 2.0 technologies for engagement is gaining momentum within the health sector however this is still in its infancy in biobanking research. This paper reports on findings from focus groups with biobank participants to gauge their views on a Web 2.0 dynamic consent interface. The findings from this study suggest that participants would welcome more interactive engagement with biobanks, and the opportunity to hear more about how their data and samples are being used in research. We propose that by adopting Web 2.0 tools for dynamic consent, we can move towards an `Engagement 2.0' model whereby research participants have the opportunity for more interactive engagement with medical research, setting up a two-way communication channel between participants and researchers, for the benefit of both.},
  pmcid = {PMC6001239},
  pmid = {29942545},
  keywords = {dynamic consent,patient engagement,research informatics,research methods}
}

@article{zeb,
  title = {Pediatric Clinical Research Networks: {{Role}} in Accelerating Development of Therapeutics in Children},
  author = {Greenberg, Rachel G. and McCune, Susan and Attar, Sabah and Hovinga, Collin and Stewart, Breanne and {Lacaze-Masmonteil}, Thierry},
  year = 2022,
  journal = {Therapeutic Innovation \& Regulatory Science},
  volume = {56},
  number = {6},
  pages = {934--947},
  issn = {2168-4790},
  doi = {10.1007/s43441-022-00453-6},
  abstract = {Recent decades have seen many advances in policy and legislation that support the development of drugs used by neonates, infants, children, and young people. This review summarizes the characteristics and performance of networks capable of conducting studies needed to meet regulatory requirements and make advances in pediatric drug development. Description of network goals and capabilities by network leaders. In the United States, Europe, Japan, and Canada, clinical research networks have been organized to meet the needs of biopharmaceutical and academic sponsors for timely access to high-quality sites, as well as to provide advice about drug development with regard to strategic and operational feasibility. Each network addresses the specificities of its context while working toward shared principles including standards and timelines; alignment of goals and processes, while not disturbing arrangements for conducting trials that work well; wide geographic coverage; all age groups and pediatric conditions; sources of funding; sites that compete on performance; performance monitoring for benchmarking, and opportunities to optimize the allocation of resources; and education and training for network members. Facilitation in interactions among these networks is based on a single point-of-contact for each; similar approaches to strategic and operational feasibility assessment, and site selection; and collaborative approaches to education and training. Within five years, clinical research networks will support the needs of biopharmaceutical and publicly funded pediatric drug development through locally appropriate and globally interoperable approaches.},
  pmcid = {PMC9462608},
  pmid = {36085251},
  keywords = {\research informatics,\research methods}
}
